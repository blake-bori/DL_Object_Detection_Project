{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Computer_Vision_Team_Project.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sswon314/DL_Object_Detection_Project/blob/master/Computer_Vision_Team_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qgaJh-BaTStR"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gDrive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utils"
      ],
      "metadata": {
        "id": "Qmh1iGMLTvo7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transform (이미지 변환)"
      ],
      "metadata": {
        "id": "_jrAjnafUQCc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class ColorHintTransform(object):\n",
        "    def __init__(self, size=256, mode=\"train\"):\n",
        "        super(ColorHintTransform, self).__init__()\n",
        "        self.size = size\n",
        "        self.mode = mode\n",
        "        self.transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "    def bgr_to_lab(self, img):\n",
        "        # rgb 값을 lab로 변경\n",
        "        lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
        "        # l은 명도(gray), ab는 채색?인듯\n",
        "        l, ab = lab[:, :, 0], lab[:, :, 1:]\n",
        "        return l, ab\n",
        "\n",
        "    def hint_mask(self, bgr, threshold=[0.95, 0.97, 0.99]):\n",
        "        h, w, c = bgr.shape\n",
        "        mask_threshold = random.choice(threshold)\n",
        "        # h*w*1 크기의 매트릭스에 T or F로 (랜덤값이 threshold보다 크면 T)\n",
        "        mask = np.random.random([h, w, 1]) > mask_threshold \n",
        "        return mask\n",
        "\n",
        "    def img_to_mask(self, mask_img):\n",
        "        mask = mask_img[:, :, 0, np.newaxis] >= 255\n",
        "        return mask\n",
        "\n",
        "    def __call__(self, img, mask_img=None):\n",
        "        threshold = [0.95, 0.97, 0.99]\n",
        "        if (self.mode == \"train\") | (self.mode == \"val\"):\n",
        "            image = cv2.resize(img, (self.size, self.size))\n",
        "            mask = self.hint_mask(image, threshold)\n",
        "\n",
        "            # hint mask에서 true 인 부분의 픽셀만 값을 가짐\n",
        "            hint_image = image * mask\n",
        "\n",
        "            # 이미지의 l, ab값 추출\n",
        "            # 힌트 이미지(특정 픽셀만 보이는 이미지)의 l, ab값 추출\n",
        "            l, ab = self.bgr_to_lab(image)\n",
        "            l_hint, ab_hint = self.bgr_to_lab(hint_image)\n",
        "\n",
        "            # 각각의 값을 tensor로 변환해서 반환\n",
        "            return self.transform(l), self.transform(ab), self.transform(ab_hint)\n",
        "\n",
        "        elif self.mode == \"test\":\n",
        "            image = cv2.resize(img, (self.size, self.size))\n",
        "            hint_image = image * self.img_to_mask(mask_img)\n",
        "\n",
        "            l, _ = self.bgr_to_lab(image)\n",
        "            _, ab_hint = self.bgr_to_lab(hint_image)\n",
        "\n",
        "            return self.transform(l), self.transform(ab_hint)\n",
        "\n",
        "        else:\n",
        "            return NotImplementedError"
      ],
      "metadata": {
        "id": "NOjxJnclURZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Unzip"
      ],
      "metadata": {
        "id": "jAXFHtBSTzt1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 드라이브에 있는 데이터 zip 파일 압축 해제\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Train, Val 데이터 압축해제\n",
        "trainFileName=\"colorization_dataset.zip\"\n",
        "trainZipPath=\"/content/gDrive/MyDrive/CV/colorization_dataset.zip\"\n",
        "\n",
        "# zip path에 있는 현재 디렉토리에 복사 -> 압축해제 -> 복사한 zip파일 삭제\n",
        "!cp \"{trainZipPath}\" .\n",
        "!unzip -q \"{trainFileName}\"\n",
        "!rm \"{trainFileName}\"\n",
        "\n",
        "\n",
        "# Test 데이터 압축해제\n",
        "testFileName=\"test_dataset.zip\"\n",
        "testZipPath=\"/content/gDrive/MyDrive/CV/test_dataset.zip\"\n",
        "\n",
        "# zip path에 있는 현재 디렉토리에 복사 -> 압축해제 -> 복사한 zip파일 삭제\n",
        "!cp \"{testZipPath}\" .\n",
        "!unzip -q \"{testFileName}\" -d \"cv_project\"\n",
        "!rm \"{testFileName}\"\n",
        "\n",
        "\n",
        "# 압축 해제 후 디렉토리\n",
        "# cv_project\n",
        "#   └ train\n",
        "#   └ val\n",
        "#   └ test_dataset\n",
        "#       └ hint\n",
        "#       └ mask"
      ],
      "metadata": {
        "id": "MwvE0zYaV25R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DataLoader"
      ],
      "metadata": {
        "id": "okK449lmtgrn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.utils.data as data\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "\n",
        "class ColorHintDataset(data.Dataset):\n",
        "    def __init__(self, root_path, size, mode=\"train\"):\n",
        "        super(ColorHintDataset, self).__init__()\n",
        "\n",
        "        self.root_path = root_path\n",
        "        self.size = size\n",
        "        self.mode = mode\n",
        "        self.transforms = ColorHintTransform(self.size, self.mode)\n",
        "        self.examples = None\n",
        "        self.hint = None\n",
        "        self.mask = None\n",
        "\n",
        "        if self.mode == \"train\":\n",
        "            train_dir = os.path.join(self.root_path, \"train\")\n",
        "            self.examples = [os.path.join(self.root_path, \"train\", dirs) for dirs in os.listdir(train_dir)]\n",
        "        elif self.mode == \"val\":\n",
        "            val_dir = os.path.join(self.root_path, \"val\")\n",
        "            self.examples = [os.path.join(self.root_path, \"val\", dirs) for dirs in os.listdir(val_dir)]\n",
        "        elif self.mode == \"test\":\n",
        "            hint_dir = os.path.join(self.root_path, \"test_dataset/hint\")\n",
        "            mask_dir = os.path.join(self.root_path, \"test_dataset/mask\")\n",
        "            self.hint = [os.path.join(self.root_path, \"test_dataset/hint\", dirs) for dirs in os.listdir(hint_dir)]\n",
        "            self.mask = [os.path.join(self.root_path, \"test_dataset/mask\", dirs) for dirs in os.listdir(mask_dir)]\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "\n",
        "    def __len__(self):\n",
        "        if self.mode != \"test\":\n",
        "            return len(self.examples)\n",
        "        else:\n",
        "            return len(self.hint)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.mode == \"test\":\n",
        "            hint_file_name = self.hint[idx]\n",
        "            mask_file_name = self.mask[idx]\n",
        "            hint_img = cv2.imread(hint_file_name)\n",
        "            mask_img = cv2.imread(mask_file_name)\n",
        "\n",
        "            input_l, input_hint = self.transforms(hint_img, mask_img)\n",
        "            sample = {\"l\": input_l, \"hint\": input_hint,\n",
        "                      \"file_name\": \"image_%06d.png\" % int(os.path.basename(hint_file_name).split('.')[0])}\n",
        "        else:\n",
        "            file_name = self.examples[idx]\n",
        "            img = cv2.imread(file_name)\n",
        "            l, ab, hint = self.transforms(img)\n",
        "            sample = {\"l\": l, \"ab\": ab, \"hint\": hint}\n",
        "\n",
        "        return sample"
      ],
      "metadata": {
        "id": "uny_mLAXTxW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.utils.data as data\n",
        "import cv2\n",
        "import tqdm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as img\n",
        "\n",
        "# 텐서를 이미지로 변환\n",
        "def tensor2im(input_image, imtype=np.uint8):\n",
        "    if isinstance(input_image, torch.Tensor):\n",
        "        image_tensor = input_image.data\n",
        "    else:\n",
        "        return input_image\n",
        "    image_numpy = image_tensor[0].cpu().float().numpy()\n",
        "    if image_numpy.shape[0] == 1:\n",
        "        image_numpy = np.tile(image_numpy, (3, 1, 1))\n",
        "    image_numpy = np.clip((np.transpose(image_numpy, (1, 2, 0))), 0, 1) * 255.0\n",
        "    return image_numpy.astype(imtype)\n",
        "\n",
        "\n",
        "# Change to your data root directory\n",
        "root_path = \"cv_project\"\n",
        "# Depend on runtime setting\n",
        "use_cuda = True\n",
        "# use_cuda = torch.cuda.is_available()\n",
        "\n",
        "train_dataset = ColorHintDataset(root_path, 256, \"train\")\n",
        "train_dataloader = data.DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
        "\n",
        "val_dataset = ColorHintDataset(root_path, 256, \"val\")\n",
        "val_dataloader = data.DataLoader(val_dataset, batch_size=4, shuffle=False)\n",
        "\n",
        "test_dataset = ColorHintDataset(root_path, 256, \"test\")\n",
        "test_dataloader = data.DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "print('train dataset length:' , len(train_dataloader)) \n",
        "print('val dataset length: ', len(val_dataloader))\n",
        "print('test dataset length: ', len(test_dataloader))"
      ],
      "metadata": {
        "id": "dWDcJUhyUVbx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 이미지 변환 결과 확인"
      ],
      "metadata": {
        "id": "cYbZiHlTDX1W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def checkImage(dataloader, mode):\n",
        "  if mode==\"train\" or mode==\"val\":\n",
        "    # 트레이닝or검증 이미지 샘플 보기\n",
        "    for i, data in enumerate(tqdm.tqdm(dataloader)):\n",
        "      if use_cuda:\n",
        "          l = data[\"l\"].to('cuda')\n",
        "          ab = data[\"ab\"].to('cuda')\n",
        "          hint = data[\"hint\"].to('cuda')\n",
        "      else:\n",
        "          l = data[\"l\"]\n",
        "          ab = data[\"ab\"]\n",
        "          hint = data[\"hint\"]\n",
        "\n",
        "      # 실제 이미지 = l, ab를 합친 이미지\n",
        "      gt_image = torch.cat((l, ab), dim=1)\n",
        "\n",
        "      # 힌트 이미지 = l, 힌트ab(특정 필셀)을 합친 이미지\n",
        "      hint_image = torch.cat((l, hint), dim=1)\n",
        "\n",
        "      gt_np = tensor2im(gt_image)\n",
        "      hint_np = tensor2im(hint_image)\n",
        "\n",
        "      # 각각의 lab이미지를 rgb로 변환\n",
        "      gt_bgr = cv2.cvtColor(gt_np, cv2.COLOR_LAB2RGB)\n",
        "      hint_bgr = cv2.cvtColor(hint_np, cv2.COLOR_LAB2RGB)\n",
        "\n",
        "      # 실제 이미지와 힌트 이미지를 따로 보여줌\n",
        "      plt.subplot(1,2,1)\n",
        "      plt.imshow(gt_bgr)\n",
        "\n",
        "      plt.subplot(1,2,2)\n",
        "      plt.imshow(hint_bgr)\n",
        "      plt.show()\n",
        "\n",
        "      # input()\n",
        "    \n",
        "  elif mode==\"test\":\n",
        "    # 테스트 이미지 샘플 보기\n",
        "    for i, data in enumerate(tqdm.tqdm(test_dataloader)):\n",
        "      if use_cuda:\n",
        "        l = data[\"l\"].to('cuda')\n",
        "        hint = data[\"hint\"].to('cuda')\n",
        "      else:\n",
        "        l = data[\"l\"]\n",
        "        hint = data[\"hint\"]\n",
        "\n",
        "      # 힌트 이미지 = l, 힌트(특정 필셀)을 합친 이미지\n",
        "      hint_image = torch.cat((l, hint), dim=1)\n",
        "      hint_np = tensor2im(hint_image)\n",
        "\n",
        "      # 각각의 lab이미지를 rgb로 변환\n",
        "      hint_bgr = cv2.cvtColor(hint_np, cv2.COLOR_LAB2RGB)\n",
        "\n",
        "      # 테스트용 이미지를 따로 보여줌\n",
        "      plt.figure(1)\n",
        "      plt.imshow(hint_bgr)\n",
        "      plt.show()\n",
        "\n",
        "      # input()\n",
        "    \n",
        "# checkImage(train_dataloader,\"train\")\n",
        "# checkImage(val_dataloader,\"val\")\n",
        "# checkImage(test_dataloader,\"test\")"
      ],
      "metadata": {
        "id": "FzEzJQqkvpHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main Code"
      ],
      "metadata": {
        "id": "V_oTawNUUUFG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Network"
      ],
      "metadata": {
        "id": "fLvD39aNs5iH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, nin, nout):\n",
        "        super().__init__()\n",
        "        self.double_conv = nn.Sequential(nn.Conv2d(nin, nout, 3, padding=1, stride=1),\n",
        "                                         nn.BatchNorm2d(nout),\n",
        "                                         nn.ReLU(inplace=True),\n",
        "                                         nn.Conv2d(nout, nout, 3, padding=1, stride=1),\n",
        "                                         nn.BatchNorm2d(nout),\n",
        "                                         nn.ReLU(inplace=True)\n",
        "                                         )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n",
        "\n",
        "\n",
        "class Down(nn.Module):\n",
        "    def __init__(self, nin, nout):\n",
        "        super().__init__()\n",
        "        self.down_conv = nn.Sequential(nn.MaxPool2d(2),\n",
        "                                       DoubleConv(nin, nout))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.down_conv(x)\n",
        "\n",
        "\n",
        "class Up(nn.Module):\n",
        "    def __init__(self, nin, nout):\n",
        "        super().__init__()\n",
        "        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        self.up_conv = DoubleConv(nin, nout)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "        # padding\n",
        "        diffY = x2.size()[2] - x1.size()[2]\n",
        "        diffX = x2.size()[3] - x1.size()[3]\n",
        "        x1 = F.pad(x1, (diffX // 2, diffX - diffX // 2,\n",
        "                        diffY // 2, diffY - diffY // 2))\n",
        "\n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        x = self.up_conv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class OutConv(nn.Module):\n",
        "    def __init__(self, nin, nout):\n",
        "        super(OutConv, self).__init__()\n",
        "        self.conv = nn.Conv2d(nin, nout, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "class MyUNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyUNet, self).__init__()\n",
        "        self.in_conv = DoubleConv(3, 64)\n",
        "        self.down1 = Down(64, 128)\n",
        "        self.down2 = Down(128, 256)\n",
        "        self.down3 = Down(256, 512)\n",
        "        self.down4 = Down(512, 1024 // 2)\n",
        "        self.up1 = Up(1024, 512 //  2)\n",
        "        self.up2 = Up(512, 256 // 2)\n",
        "        self.up3 = Up(256, 128 // 2)\n",
        "        self.up4 = Up(128, 64)\n",
        "        self.out_conv = OutConv(64, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.in_conv(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.down4(x4)\n",
        "        x = self.up1(x5, x4)\n",
        "        x = self.up2(x, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        x = self.out_conv(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "XHMVv5Dr_ZT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/ousinkou/Gachon_SW_Colorization_Contest\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class upsample_block(nn.Module):\n",
        "    def __init__(self, ch_in, ch_out):\n",
        "        super(upsample_block, self).__init__()\n",
        "\n",
        "        self.up = nn.Sequential(\n",
        "            nn.Conv2d(ch_in,ch_out,3,1,1),\n",
        "            nn.BatchNorm2d(ch_out),\n",
        "            nn.ReLU(inplace=True ),\n",
        "            nn.ConvTranspose2d(ch_out , ch_out , 3,2,1,1),\n",
        "            nn.BatchNorm2d(ch_out),\n",
        "            nn.ReLU(inplace=True )\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.up(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class Residual_recurrent_block(nn.Module):\n",
        "    def __init__(self, ch_in, ch_out):\n",
        "        super(Residual_recurrent_block, self).__init__()\n",
        "\n",
        "        self.RCNN = nn.Sequential(\n",
        "            nn.Conv2d(ch_out, ch_out, kernel_size=3, stride=1, padding=1, bias=True),\n",
        "            nn.BatchNorm2d(ch_out),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(ch_out, ch_out, kernel_size=3, stride=1, padding=1, bias=True),\n",
        "            nn.BatchNorm2d(ch_out)\n",
        "            #nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.Conv_1x1 = nn.Conv2d(ch_in, ch_out, kernel_size=1, stride=1, padding=0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.Conv_1x1(x)\n",
        "\n",
        "        x1 = self.RCNN(x)\n",
        "        return x + x1\n",
        "\n",
        "\n",
        "\n",
        "class Attention_block(nn.Module):\n",
        "    def __init__(self, upsample, downsample, ch_result):\n",
        "        super(Attention_block, self).__init__()\n",
        "\n",
        "        self.skip = nn.Sequential(\n",
        "            nn.Conv2d(upsample, ch_result, kernel_size=1, stride=1, padding=0, bias=True),\n",
        "            nn.BatchNorm2d(ch_result)\n",
        "        )\n",
        "\n",
        "        self.up = nn.Sequential(\n",
        "            nn.Conv2d(downsample, ch_result, kernel_size=1, stride=1, padding=0, bias=True),\n",
        "            nn.BatchNorm2d(ch_result)\n",
        "        )\n",
        "\n",
        "        self.concat = nn.Sequential(\n",
        "            nn.Conv2d(ch_result, 1, kernel_size=1, stride=1, padding=0, bias=True),\n",
        "            nn.BatchNorm2d(1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, g, x):\n",
        "        s1 = self.skip(g)\n",
        "\n",
        "        u1 = self.up(x)\n",
        "        attd = self.relu(s1 + u1)\n",
        "        attd = self.concat(attd)\n",
        "\n",
        "        return x * attd\n",
        "\n",
        "class ResAttdU_Net(nn.Module):\n",
        "    def __init__(self, img_ch=3, output_ch=3):\n",
        "        super(ResAttdU_Net, self).__init__()\n",
        "\n",
        "        self.Maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.DownSample1 = Residual_recurrent_block(ch_in=img_ch, ch_out=64 )\n",
        "        self.DownSample1_1 = Residual_recurrent_block(ch_in=64 , ch_out=64)\n",
        "\n",
        "        self.DownSample2 = Residual_recurrent_block(ch_in=64, ch_out=128)\n",
        "        self.DownSample2_1 = Residual_recurrent_block(ch_in=128, ch_out=128)\n",
        "\n",
        "        self.DownSample3 = Residual_recurrent_block(ch_in=128, ch_out=256)\n",
        "        self.DownSample3_1 = Residual_recurrent_block(ch_in=256, ch_out=256)\n",
        "\n",
        "        self.DownSample4 = Residual_recurrent_block(ch_in=256, ch_out=512 )\n",
        "        self.DownSample4_1 = Residual_recurrent_block(ch_in=512, ch_out=512)\n",
        "\n",
        "        self.DownSample5 = Residual_recurrent_block(ch_in=512, ch_out=1024)\n",
        "        self.DownSample5_1 = Residual_recurrent_block(ch_in=1024, ch_out=1024)\n",
        "\n",
        "        self.Up5 = upsample_block(ch_in=1024, ch_out=512)\n",
        "        self.Att5 = Attention_block(upsample=512, downsample=512, ch_result=256)\n",
        "        self.UpSample5 = Residual_recurrent_block(ch_in=1024, ch_out=512)\n",
        "        self.UpSample5_1 = Residual_recurrent_block(ch_in=512, ch_out=512)\n",
        "\n",
        "        self.Up4 = upsample_block(ch_in=512, ch_out=256)\n",
        "        self.Att4 = Attention_block(upsample=256, downsample=256, ch_result=128)\n",
        "        self.UpSample4 = Residual_recurrent_block(ch_in=512, ch_out=256 )\n",
        "        self.UpSample4_1 = Residual_recurrent_block(ch_in=256, ch_out=256)\n",
        "\n",
        "        self.Up3 = upsample_block(ch_in=256, ch_out=128)\n",
        "        self.Att3 = Attention_block(upsample=128, downsample=128, ch_result=64)\n",
        "        self.UpSample3 = Residual_recurrent_block(ch_in=256, ch_out=128 )\n",
        "        self.UpSample3_1 = Residual_recurrent_block(ch_in=128, ch_out=128)\n",
        "\n",
        "        self.Up2 = upsample_block(ch_in=128, ch_out=64)\n",
        "        self.Att2 = Attention_block(upsample=64, downsample=64, ch_result=32)\n",
        "        self.UpSample2 = Residual_recurrent_block(ch_in=128, ch_out=64)\n",
        "        self.UpSample2_1 = Residual_recurrent_block(ch_in=64, ch_out=64)\n",
        "\n",
        "        self.Conv_1x1 = nn.Conv2d(64, output_ch, kernel_size=1, stride=1, padding=0)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # encoding path\n",
        "        x1 = self.DownSample1(x)\n",
        "        x1 = self.DownSample1_1(x1)\n",
        "\n",
        "        x2 = self.Maxpool(x1)\n",
        "        x2 = self.DownSample2(x2)\n",
        "        x2 = self.DownSample2_1(x2)\n",
        "\n",
        "        x3 = self.Maxpool(x2)\n",
        "        x3 = self.DownSample3(x3)\n",
        "        x3 = self.DownSample3_1(x3)\n",
        "\n",
        "        x4 = self.Maxpool(x3)\n",
        "        x4 = self.DownSample4(x4)\n",
        "        x4 = self.DownSample4_1(x4)\n",
        "\n",
        "        x5 = self.Maxpool(x4)\n",
        "        x5 = self.DownSample5(x5)\n",
        "        x5 = self.DownSample5_1(x5)\n",
        "\n",
        "        d5 = self.Up5(x5)\n",
        "        x4 = self.Att5(g=d5, x=x4)\n",
        "        d5 = torch.cat((x4, d5), dim=1)\n",
        "        d5 = self.UpSample5(d5)\n",
        "        d5 = self.UpSample5_1(d5)\n",
        "\n",
        "        d4 = self.Up4(d5)\n",
        "        x3 = self.Att4(g=d4, x=x3)\n",
        "        d4 = torch.cat((x3, d4), dim=1)\n",
        "        d4 = self.UpSample4(d4)\n",
        "        d4 = self.UpSample4_1(d4)\n",
        "\n",
        "        d3 = self.Up3(d4)\n",
        "        x2 = self.Att3(g=d3, x=x2)\n",
        "        d3 = torch.cat((x2, d3), dim=1)\n",
        "        d3 = self.UpSample3(d3)\n",
        "        d3 = self.UpSample3_1(d3)\n",
        "\n",
        "        d2 = self.Up2(d3)\n",
        "        x1 = self.Att2(g=d2, x=x1)\n",
        "        d2 = torch.cat((x1, d2), dim=1)\n",
        "        d2 = self.UpSample2(d2)\n",
        "        d2 = self.UpSample2_1(d2)\n",
        "\n",
        "        d1 = self.Conv_1x1(d2)\n",
        "\n",
        "        return d1"
      ],
      "metadata": {
        "id": "WDqO3cUXs6k7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/psyrocloud/MS-SSIM_L1_LOSS\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class MS_SSIM_L1_LOSS(nn.Module):\n",
        "    # Have to use cuda, otherwise the speed is too slow.\n",
        "    def __init__(self, gaussian_sigmas=[0.5, 1.0, 2.0, 4.0, 8.0],\n",
        "                 data_range = 1.0,\n",
        "                 K=(0.01, 0.03),\n",
        "                 alpha=0.025,\n",
        "                 compensation=200.0,\n",
        "                 cuda_dev=0,):\n",
        "        super(MS_SSIM_L1_LOSS, self).__init__()\n",
        "        self.DR = data_range\n",
        "        self.C1 = (K[0] * data_range) ** 2\n",
        "        self.C2 = (K[1] * data_range) ** 2\n",
        "        self.pad = int(2 * gaussian_sigmas[-1])\n",
        "        self.alpha = alpha\n",
        "        self.compensation=compensation\n",
        "        filter_size = int(4 * gaussian_sigmas[-1] + 1)\n",
        "        g_masks = torch.zeros((3*len(gaussian_sigmas), 1, filter_size, filter_size))\n",
        "        for idx, sigma in enumerate(gaussian_sigmas):\n",
        "            # r0,g0,b0,r1,g1,b1,...,rM,gM,bM\n",
        "            g_masks[3*idx+0, 0, :, :] = self._fspecial_gauss_2d(filter_size, sigma)\n",
        "            g_masks[3*idx+1, 0, :, :] = self._fspecial_gauss_2d(filter_size, sigma)\n",
        "            g_masks[3*idx+2, 0, :, :] = self._fspecial_gauss_2d(filter_size, sigma)\n",
        "        self.g_masks = g_masks.cuda(cuda_dev)\n",
        "\n",
        "    def _fspecial_gauss_1d(self, size, sigma):\n",
        "        \"\"\"Create 1-D gauss kernel\n",
        "        Args:\n",
        "            size (int): the size of gauss kernel\n",
        "            sigma (float): sigma of normal distribution\n",
        "        Returns:\n",
        "            torch.Tensor: 1D kernel (size)\n",
        "        \"\"\"\n",
        "        coords = torch.arange(size).to(dtype=torch.float)\n",
        "        coords -= size // 2\n",
        "        g = torch.exp(-(coords ** 2) / (2 * sigma ** 2))\n",
        "        g /= g.sum()\n",
        "        return g.reshape(-1)\n",
        "\n",
        "    def _fspecial_gauss_2d(self, size, sigma):\n",
        "        \"\"\"Create 2-D gauss kernel\n",
        "        Args:\n",
        "            size (int): the size of gauss kernel\n",
        "            sigma (float): sigma of normal distribution\n",
        "        Returns:\n",
        "            torch.Tensor: 2D kernel (size x size)\n",
        "        \"\"\"\n",
        "        gaussian_vec = self._fspecial_gauss_1d(size, sigma)\n",
        "        return torch.outer(gaussian_vec, gaussian_vec)\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        b, c, h, w = x.shape\n",
        "        mux = F.conv2d(x, self.g_masks, groups=3, padding=self.pad)\n",
        "        muy = F.conv2d(y, self.g_masks, groups=3, padding=self.pad)\n",
        "\n",
        "        mux2 = mux * mux\n",
        "        muy2 = muy * muy\n",
        "        muxy = mux * muy\n",
        "\n",
        "        sigmax2 = F.conv2d(x * x, self.g_masks, groups=3, padding=self.pad) - mux2\n",
        "        sigmay2 = F.conv2d(y * y, self.g_masks, groups=3, padding=self.pad) - muy2\n",
        "        sigmaxy = F.conv2d(x * y, self.g_masks, groups=3, padding=self.pad) - muxy\n",
        "\n",
        "        # l(j), cs(j) in MS-SSIM\n",
        "        l  = (2 * muxy    + self.C1) / (mux2    + muy2    + self.C1)  # [B, 15, H, W]\n",
        "        cs = (2 * sigmaxy + self.C2) / (sigmax2 + sigmay2 + self.C2)\n",
        "\n",
        "        lM = l[:, -1, :, :] * l[:, -2, :, :] * l[:, -3, :, :]\n",
        "        PIcs = cs.prod(dim=1)\n",
        "\n",
        "        loss_ms_ssim = 1 - lM*PIcs  # [B, H, W]\n",
        "\n",
        "        loss_l1 = F.l1_loss(x, y, reduction='none')  # [B, 3, H, W]\n",
        "        # average l1 loss in 3 channels\n",
        "        gaussian_l1 = F.conv2d(loss_l1, self.g_masks.narrow(dim=0, start=-3, length=3),\n",
        "                               groups=3, padding=self.pad).mean(1)  # [B, H, W]\n",
        "\n",
        "        loss_mix = self.alpha * loss_ms_ssim + (1 - self.alpha) * gaussian_l1 / self.DR\n",
        "        loss_mix = self.compensation*loss_mix\n",
        "\n",
        "        return loss_mix.mean()"
      ],
      "metadata": {
        "id": "MZ-FEPbQVyFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train"
      ],
      "metadata": {
        "id": "PK97kzHOG9Sv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련 결과 저장 위치\n",
        "# 훈련 결과 저장 위치는 드라이브에 설정해서 나중에 불러와서 쓸 수 있도록 함\n",
        "save_path = '/content/gDrive/MyDrive/CV'\n",
        "os.makedirs(save_path, exist_ok= True)\n",
        "best_output_path = os.path.join(save_path, 'best_model.tar')  # 가장 좋은 성능 모델\n",
        "last_output_path = os.path.join(save_path, 'last_model.tar')  # 마지막으로 학습한 모델\n",
        "\n",
        "### 하이퍼파라미터 ###\n",
        "# 한번에 학습할 epoch수\n",
        "EPOCH=100\n",
        "LR = 0.0005\n",
        "\n",
        "# 모델 설정\n",
        "# trainNet = MyUNet().cuda()\n",
        "trainNet = ResAttdU_Net().cuda()\n",
        "\n",
        "# loss function 및 optimizer 설정\n",
        "import torch.optim as optim\n",
        "# criterion = nn.L1Loss()\n",
        "criterion = MS_SSIM_L1_LOSS()\n",
        "optimizer = torch.optim.Adam(trainNet.parameters(), lr=LR)\n",
        "\n",
        "\n",
        "# 이전에 학습했던 모델이 있으면 그 모델의 weight값으로 설정\n",
        "# state_dict = memo, epoch, best_loss, train_info, val_info, model_weight, optim_state\n",
        "if os.path.isfile(last_output_path):\n",
        "  print(\"체크포인트 불러옴\")\n",
        "  state_dict=torch.load(last_output_path)\n",
        "  train_info = state_dict[\"train_info\"]\n",
        "  val_info = state_dict[\"val_info\"]\n",
        "  best_loss = state_dict[\"best_loss\"]\n",
        "  start_epoch=state_dict[\"epoch\"]+1\n",
        "  print(\"Epoch {}번부터 시작\".format(start_epoch))\n",
        "\n",
        "  trainNet.load_state_dict(state_dict['model_weight'])\n",
        "\n",
        "# 없으면 기본 값 사용\n",
        "else:\n",
        "  print(\"체크포인트 없음\")\n",
        "  train_info=[]\n",
        "  val_info=[]\n",
        "  best_loss = 100\n",
        "  start_epoch=0"
      ],
      "metadata": {
        "id": "H17r5Wu2GXfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training 시킬 함수\n",
        "def train_model(net, train_dataloader):\n",
        "  total_loss = 0\n",
        "  iteration = 0\n",
        "  net.train()\n",
        "\n",
        "  for i, data in enumerate(tqdm.auto.tqdm(train_dataloader)):\n",
        "    if use_cuda:\n",
        "      l_imgs = data[\"l\"].to('cuda')\n",
        "      ab_imgs = data[\"ab\"].to('cuda')\n",
        "      hint_imgs = data[\"hint\"].to('cuda')\n",
        "    else:\n",
        "      l_imgs = data[\"l\"]\n",
        "      ab_imgs = data[\"ab\"]\n",
        "      hint_imgs = data[\"hint\"]\n",
        "\n",
        "    gt_image = torch.cat((l_imgs,ab_imgs), dim=1)\n",
        "    hint_image = torch.cat((l_imgs, hint_imgs), dim=1)\n",
        "\n",
        "    gt_image = gt_image.float().cuda()\n",
        "    hint_image = hint_image.float().cuda()\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    output = net(hint_image).squeeze(1)\n",
        "    # output = torch.cat((l_imgs, output), dim=1)\n",
        "\n",
        "    loss = criterion(output, gt_image)\n",
        "    # loss = criterion(output, ab_imgs)\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "    total_loss += loss.detach()\n",
        "    iteration += 1\n",
        "  \n",
        "  total_loss /= iteration\n",
        "  return total_loss\n",
        "\n",
        "# Validation 시킬 함수\n",
        "def val_model(net, val_dataloader):\n",
        "  total_loss = 0\n",
        "  iteration = 0\n",
        "  net.eval()\n",
        "\n",
        "  for i, data in enumerate(tqdm.auto.tqdm(val_dataloader)):\n",
        "    if use_cuda:\n",
        "      l_imgs = data[\"l\"].to('cuda')\n",
        "      ab_imgs = data[\"ab\"].to('cuda')\n",
        "      hint_imgs = data[\"hint\"].to('cuda')\n",
        "    else:\n",
        "      l_imgs = data[\"l\"]\n",
        "      ab_imgs = data[\"ab\"]\n",
        "      hint_imgs = data[\"hint\"]\n",
        "\n",
        "    gt_image = torch.cat((l_imgs,ab_imgs), dim=1)\n",
        "    hint_image = torch.cat((l_imgs, hint_imgs), dim=1)\n",
        "\n",
        "    gt_image = gt_image.float().cuda()\n",
        "    hint_image = hint_image.float().cuda()\n",
        "   \n",
        "    output = net(hint_image).squeeze(1)\n",
        "    # output = torch.cat((l_imgs, output), dim=1)\n",
        "\n",
        "    loss = criterion(output, gt_image)\n",
        "    # loss = criterion(output, ab_imgs)\n",
        "\n",
        "    total_loss += loss.detach()\n",
        "    iteration += 1\n",
        "\n",
        "  total_loss /= iteration\n",
        "  return total_loss"
      ],
      "metadata": {
        "id": "r0PotxZbhtEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이전 학습 모델의 다음 epoch부터 n번 실행\n",
        "for epoch in range(start_epoch,start_epoch+EPOCH):\n",
        "  t_loss = train_model(trainNet, train_dataloader)\n",
        "  print('[TRAINING] Epoch: {} train_score: {}'.format(epoch, t_loss))\n",
        "  train_info.append({'loss': t_loss})\n",
        "\n",
        "  with torch.no_grad():\n",
        "    v_loss = val_model(trainNet, val_dataloader)\n",
        "    print('[VALIDATION] Epoch: {} loss: {}'.format(epoch, v_loss))\n",
        "    val_info.append({'loss': v_loss})\n",
        "  \n",
        "  # 검증 loss가 제일 모델 저장\n",
        "  if best_loss > v_loss:\n",
        "    best_loss = v_loss\n",
        "    print(\"최고 성능 모델 저장\")\n",
        "    torch.save({\n",
        "      \"memo\": \"This is Best Model\",\n",
        "      \"epoch\": epoch,\n",
        "      \"best_loss\": best_loss,\n",
        "      \"train_info\":train_info,\n",
        "      \"val_info\":val_info,\n",
        "      \"model_weight\":trainNet.state_dict(),\n",
        "    }, best_output_path)\n",
        "\n",
        "  # 해당 epoch에 대한 모델 저장\n",
        "  print(\"{}번째 모델 저장\".format(epoch))\n",
        "  torch.save({\n",
        "      \"memo\": \"This is Last Model\",\n",
        "      \"epoch\": epoch,\n",
        "      \"best_loss\": best_loss,\n",
        "      \"train_info\":train_info,\n",
        "      \"val_info\":val_info,\n",
        "      \"model_weight\":trainNet.state_dict(),\n",
        "  }, last_output_path)"
      ],
      "metadata": {
        "id": "_t2LjOkv9Fy7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test"
      ],
      "metadata": {
        "id": "3TTzbyFw8f6v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing 시킬 함수\n",
        "def test_model(net, test_dataloader):\n",
        "  net.eval()\n",
        "  for i, data in enumerate(tqdm.auto.tqdm(test_dataloader)):\n",
        "    if use_cuda:\n",
        "        l = data[\"l\"].to('cuda')\n",
        "        hint = data[\"hint\"].to('cuda')\n",
        "    else:\n",
        "        l = data[\"l\"]\n",
        "        hint = data[\"hint\"]\n",
        "\n",
        "    hint_image = torch.cat((l, hint), dim=1)\n",
        "    hint_np = tensor2im(hint_image)\n",
        "    hint_image = hint_image.float().cuda()\n",
        "\n",
        "    output = net(hint_image).squeeze(1)\n",
        "    # output = torch.cat((l, output), dim=1)\n",
        "    output_np = tensor2im(output)\n",
        "\n",
        "    hint_bgr = cv2.cvtColor(hint_np, cv2.COLOR_LAB2RGB)\n",
        "    output_bgr = cv2.cvtColor(output_np, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "    # 결과 이미지 저장 (제출용)\n",
        "    os.makedirs('cv_project/outputs/', exist_ok=True) \n",
        "    i = str(i).zfill(6)\n",
        "    cv2.imwrite('cv_project/outputs/' + data['file_name'][0], output_bgr)\n",
        "\n",
        "    # 테스트 이미지와 결과 이미지를 동시에 보여줌\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.imshow(hint_bgr)\n",
        "\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.imshow(output_bgr)\n",
        "    plt.show()\n",
        "\n",
        "    # 아무 값이나 입력해서 다음 이미지 표시\n",
        "    # input 빼면 자동 저장\n",
        "    # input()"
      ],
      "metadata": {
        "id": "1-UjqGbAx0zA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "save_path = '/content/gDrive/MyDrive/CV'\n",
        "last_model_path = os.path.join(save_path, 'last_model.tar')\n",
        "best_model_path = os.path.join(save_path, 'best_model.tar')\n",
        "\n",
        "if os.path.isfile(last_model_path):\n",
        "  last_state_dict=torch.load(last_model_path)\n",
        "  print(\"Epoch {}까지 돌렸음\".format(last_state_dict[\"epoch\"]))\n",
        "  epochAxis=np.arange(0, len(last_state_dict[\"train_info\"]))\n",
        "\n",
        "  plt.title(\"LOSS\")\n",
        "  plt.plot(epochAxis, [info[\"loss\"].cpu() for info in last_state_dict[\"train_info\"]], epochAxis, [info[\"loss\"].cpu() for info in last_state_dict[\"val_info\"]], \"r-\")\n",
        "  plt.legend([\"TRAIN\",\"VALIDATION\"])\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "if os.path.isfile(best_model_path):\n",
        "  best_state_dict=torch.load(best_model_path)\n",
        "  print(\"Epoch {}일때 최고 성능이었음\".format(best_state_dict[\"epoch\"]))\n",
        "\n",
        "  testNet = ResAttdU_Net().cuda()\n",
        "  # testNet = MyUNet().cuda()\n",
        "\n",
        "  testNet.load_state_dict(best_state_dict['model_weight'])\n",
        "\n",
        "  test_model(testNet, test_dataloader)"
      ],
      "metadata": {
        "id": "jn8E95UV9HRP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}